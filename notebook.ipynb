{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/150244868769783183', creation_time=1691158569332, experiment_id='150244868769783183', last_update_time=1691158569332, lifecycle_stage='active', name='StemToken', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/771411303543058092', creation_time=1691158216829, experiment_id='771411303543058092', last_update_time=1691158216829, lifecycle_stage='active', name='LemmaToken', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/761930417213375925', creation_time=1691151573324, experiment_id='761930417213375925', last_update_time=1691151573324, lifecycle_stage='active', name='RawToken', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1691118511104, experiment_id='0', last_update_time=1691118511104, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StemToken 150244868769783183\n",
      "LemmaToken 771411303543058092\n",
      "RawToken 761930417213375925\n",
      "Default 0\n"
     ]
    }
   ],
   "source": [
    "for exp in mlflow.search_experiments():\n",
    "    print(exp.name, exp.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('artifact_location', 'mlflow-artifacts:/771411303543058092')\n",
      "('creation_time', 1691158216829)\n",
      "('experiment_id', '771411303543058092')\n",
      "('last_update_time', 1691158216829)\n",
      "('lifecycle_stage', 'active')\n",
      "('name', 'LemmaToken')\n",
      "('tags', {})\n"
     ]
    }
   ],
   "source": [
    "for i in exp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = mlflow.search_runs(experiment_ids=[761930417213375925])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 17 columns):\n",
      " #   Column                         Non-Null Count  Dtype              \n",
      "---  ------                         --------------  -----              \n",
      " 0   run_id                         4 non-null      object             \n",
      " 1   experiment_id                  4 non-null      object             \n",
      " 2   status                         4 non-null      object             \n",
      " 3   artifact_uri                   4 non-null      object             \n",
      " 4   start_time                     4 non-null      datetime64[ns, UTC]\n",
      " 5   end_time                       4 non-null      datetime64[ns, UTC]\n",
      " 6   metrics.Test Accuracy          4 non-null      float64            \n",
      " 7   metrics.F1 Score               4 non-null      float64            \n",
      " 8   metrics.Training Accuracy      4 non-null      float64            \n",
      " 9   params.n_estimators            4 non-null      object             \n",
      " 10  params.Maximum Depth           4 non-null      object             \n",
      " 11  params.Criterion               4 non-null      object             \n",
      " 12  tags.mlflow.log-model.history  4 non-null      object             \n",
      " 13  tags.mlflow.user               4 non-null      object             \n",
      " 14  tags.mlflow.source.type        4 non-null      object             \n",
      " 15  tags.mlflow.runName            4 non-null      object             \n",
      " 16  tags.mlflow.source.name        4 non-null      object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(3), object(12)\n",
      "memory usage: 672.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "runs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run_ID = 'ec6ebf18026749ad8e54420838c50561'\n",
    "\n",
    "# load from run id\n",
    "logged_vect = f'runs:/{Run_ID}/vectorizer'\n",
    "logged_model = f'runs:/{Run_ID}/model'\n",
    "loaded_vect = mlflow.sklearn.load_model(logged_vect)\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = str(loaded_model).split()[-1]\n",
    "logged_vect = f'runs:/{run_id}/vectorizer'\n",
    "loaded_vect = mlflow.sklearn.load_model(logged_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_vect = f'runs:/{Run_ID}/vectorizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st  \n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text.lower())\n",
    "    # filtered_words = [word for word in words if word.isalpha()]\n",
    "    # filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    # filtered_words = [stemmer.stem(word) for word in words if word.isalpha() and word not in stop_words]\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: spam\n"
     ]
    }
   ],
   "source": [
    "text = \"URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot!\"\n",
    "\n",
    "# get the run_id\n",
    "Run_ID = 'ec6ebf18026749ad8e54420838c50561'\n",
    "\n",
    "# load from run id\n",
    "logged_vect = f'runs:/{Run_ID}/vectorizer'\n",
    "logged_model = f'runs:/{Run_ID}/model'\n",
    "loaded_vect = mlflow.sklearn.load_model(logged_vect)\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Preprocess the new raw text\n",
    "processed_text = preprocess_text(text)\n",
    "\n",
    "# Vectorize the processed text\n",
    "vectorized_text = loaded_vect.transform([processed_text])\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(vectorized_text)\n",
    "\n",
    "# Print the prediction\n",
    "print(f\"Predicted label: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: model\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: ec6ebf18026749ad8e54420838c50561"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/spamfilter/Production\")\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (loaded_model.unwrap_python_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    MLflow 'python function' model.\\n\\n    Wrapper around model implementation and metadata. This class is not meant to be constructed\\n    directly. Instead, instances of this class are constructed and returned from\\n    :py:func:`load_model() <mlflow.pyfunc.load_model>`.\\n\\n    ``model_impl`` can be any Python object that implements the `Pyfunc interface\\n    <https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#pyfunc-inference-api>`_, and is\\n    returned by invoking the model's ``loader_module``.\\n\\n    ``model_meta`` contains model metadata loaded from the MLmodel file.\\n    \""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Unable to retrieve base model object from pyfunc.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py:481\u001b[0m, in \u001b[0;36mPyFuncModel.unwrap_python_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m     python_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_impl\u001b[39m.\u001b[39;49mpython_model\n\u001b[0;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m python_model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'python_model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x()\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py:485\u001b[0m, in \u001b[0;36mPyFuncModel.unwrap_python_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected python_model attribute not to be None.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    484\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 485\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\u001b[39m\"\u001b[39m\u001b[39mUnable to retrieve base model object from pyfunc.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[39mreturn\u001b[39;00m python_model\n",
      "\u001b[1;31mMlflowException\u001b[0m: Unable to retrieve base model object from pyfunc."
     ]
    }
   ],
   "source": [
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mlflow' has no attribute 'unwrap_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m unwrapped_model \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39;49munwrap_model(loaded_model)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mlflow' has no attribute 'unwrap_model'"
     ]
    }
   ],
   "source": [
    "unwrapped_model = mlflow.unwrap_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unwrapped_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected view_type: Production",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mlflow\u001b[39m.\u001b[39;49msearch_runs(run_view_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mProduction\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\tracking\\fluent.py:1683\u001b[0m, in \u001b[0;36msearch_runs\u001b[1;34m(experiment_ids, filter_string, run_view_type, max_results, order_by, output_format, search_all_experiments, experiment_names)\u001b[0m\n\u001b[0;32m   1673\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[0;32m   1674\u001b[0m         \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39msearch_runs(\n\u001b[0;32m   1675\u001b[0m             experiment_ids,\n\u001b[0;32m   1676\u001b[0m             filter_string,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1680\u001b[0m             next_page_token,\n\u001b[0;32m   1681\u001b[0m         )\n\u001b[1;32m-> 1683\u001b[0m     runs \u001b[39m=\u001b[39m get_results_from_paginated_fn(\n\u001b[0;32m   1684\u001b[0m         pagination_wrapper_func,\n\u001b[0;32m   1685\u001b[0m         NUM_RUNS_PER_PAGE_PANDAS,\n\u001b[0;32m   1686\u001b[0m         max_results,\n\u001b[0;32m   1687\u001b[0m     )\n\u001b[0;32m   1689\u001b[0m \u001b[39mif\u001b[39;00m output_format \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mreturn\u001b[39;00m runs  \u001b[39m# List[mlflow.entities.run.Run]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\utils\\__init__.py:266\u001b[0m, in \u001b[0;36mget_results_from_paginated_fn\u001b[1;34m(paginated_fn, max_results_per_page, max_results)\u001b[0m\n\u001b[0;32m    264\u001b[0m     page_results \u001b[39m=\u001b[39m paginated_fn(num_to_get, next_page_token)\n\u001b[0;32m    265\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     page_results \u001b[39m=\u001b[39m paginated_fn(max_results_per_page, next_page_token)\n\u001b[0;32m    267\u001b[0m all_results\u001b[39m.\u001b[39mextend(page_results)\n\u001b[0;32m    268\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(page_results, \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m page_results\u001b[39m.\u001b[39mtoken:\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\tracking\\fluent.py:1674\u001b[0m, in \u001b[0;36msearch_runs.<locals>.pagination_wrapper_func\u001b[1;34m(number_to_get, next_page_token)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[1;32m-> 1674\u001b[0m     \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39;49msearch_runs(\n\u001b[0;32m   1675\u001b[0m         experiment_ids,\n\u001b[0;32m   1676\u001b[0m         filter_string,\n\u001b[0;32m   1677\u001b[0m         run_view_type,\n\u001b[0;32m   1678\u001b[0m         number_to_get,\n\u001b[0;32m   1679\u001b[0m         order_by,\n\u001b[0;32m   1680\u001b[0m         next_page_token,\n\u001b[0;32m   1681\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\tracking\\client.py:2007\u001b[0m, in \u001b[0;36mMlflowClient.search_runs\u001b[1;34m(self, experiment_ids, filter_string, run_view_type, max_results, order_by, page_token)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch_runs\u001b[39m(\n\u001b[0;32m   1917\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1918\u001b[0m     experiment_ids: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1923\u001b[0m     page_token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1924\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PagedList[Run]:\n\u001b[0;32m   1925\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1926\u001b[0m \u001b[39m    Search for Runs that fit the specified criteria.\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2005\u001b[0m \u001b[39m        tags: {'s.release': '1.1.0-RC'}\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49msearch_runs(\n\u001b[0;32m   2008\u001b[0m         experiment_ids, filter_string, run_view_type, max_results, order_by, page_token\n\u001b[0;32m   2009\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:551\u001b[0m, in \u001b[0;36mTrackingServiceClient.search_runs\u001b[1;34m(self, experiment_ids, filter_string, run_view_type, max_results, order_by, page_token)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(experiment_ids, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m is_string_type(experiment_ids):\n\u001b[0;32m    550\u001b[0m     experiment_ids \u001b[39m=\u001b[39m [experiment_ids]\n\u001b[1;32m--> 551\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49msearch_runs(\n\u001b[0;32m    552\u001b[0m     experiment_ids\u001b[39m=\u001b[39;49mexperiment_ids,\n\u001b[0;32m    553\u001b[0m     filter_string\u001b[39m=\u001b[39;49mfilter_string,\n\u001b[0;32m    554\u001b[0m     run_view_type\u001b[39m=\u001b[39;49mrun_view_type,\n\u001b[0;32m    555\u001b[0m     max_results\u001b[39m=\u001b[39;49mmax_results,\n\u001b[0;32m    556\u001b[0m     order_by\u001b[39m=\u001b[39;49morder_by,\n\u001b[0;32m    557\u001b[0m     page_token\u001b[39m=\u001b[39;49mpage_token,\n\u001b[0;32m    558\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\store\\tracking\\abstract_store.py:298\u001b[0m, in \u001b[0;36mAbstractStore.search_runs\u001b[1;34m(self, experiment_ids, filter_string, run_view_type, max_results, order_by, page_token)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch_runs\u001b[39m(\n\u001b[0;32m    272\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    273\u001b[0m     experiment_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m     page_token\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m ):\n\u001b[0;32m    280\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39m    Return runs that match the given list of search expressions within the experiments.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m        meaningful in such cases.\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     runs, token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_search_runs(\n\u001b[0;32m    299\u001b[0m         experiment_ids, filter_string, run_view_type, max_results, order_by, page_token\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m PagedList(runs, token)\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:282\u001b[0m, in \u001b[0;36mRestStore._search_runs\u001b[1;34m(self, experiment_ids, filter_string, run_view_type, max_results, order_by, page_token)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_search_runs\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[39mself\u001b[39m, experiment_ids, filter_string, run_view_type, max_results, order_by, page_token\n\u001b[0;32m    277\u001b[0m ):\n\u001b[0;32m    278\u001b[0m     experiment_ids \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(experiment_id) \u001b[39mfor\u001b[39;00m experiment_id \u001b[39min\u001b[39;00m experiment_ids]\n\u001b[0;32m    279\u001b[0m     sr \u001b[39m=\u001b[39m SearchRuns(\n\u001b[0;32m    280\u001b[0m         experiment_ids\u001b[39m=\u001b[39mexperiment_ids,\n\u001b[0;32m    281\u001b[0m         \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39mfilter_string,\n\u001b[1;32m--> 282\u001b[0m         run_view_type\u001b[39m=\u001b[39mViewType\u001b[39m.\u001b[39;49mto_proto(run_view_type),\n\u001b[0;32m    283\u001b[0m         max_results\u001b[39m=\u001b[39mmax_results,\n\u001b[0;32m    284\u001b[0m         order_by\u001b[39m=\u001b[39morder_by,\n\u001b[0;32m    285\u001b[0m         page_token\u001b[39m=\u001b[39mpage_token,\n\u001b[0;32m    286\u001b[0m     )\n\u001b[0;32m    287\u001b[0m     req_body \u001b[39m=\u001b[39m message_to_json(sr)\n\u001b[0;32m    288\u001b[0m     response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_endpoint(SearchRuns, req_body)\n",
      "File \u001b[1;32mc:\\Users\\afaqu\\WorkSpace\\SandBox\\Spamfilter\\spmf\\lib\\site-packages\\mlflow\\entities\\view_type.py:41\u001b[0m, in \u001b[0;36mViewType.to_proto\u001b[1;34m(cls, view_type)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39melif\u001b[39;00m view_type \u001b[39m==\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mALL:\n\u001b[0;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m service_pb2\u001b[39m.\u001b[39mALL\n\u001b[1;32m---> 41\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected view_type: \u001b[39m\u001b[39m{\u001b[39;00mview_type\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected view_type: Production"
     ]
    }
   ],
   "source": [
    "mlflow.search_runs(run_view_type='Production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PyFuncModel' object has no attribute 'run_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loaded_model\u001b[39m.\u001b[39;49mrun_id\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PyFuncModel' object has no attribute 'run_id'"
     ]
    }
   ],
   "source": [
    "loaded_model.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot!\"\n",
    "\n",
    "# Specify the model name and version\n",
    "model_name = \"spamfilter\"\n",
    "model_version = \"production\"\n",
    "\n",
    "# load from run id\n",
    "logged_vect = f'runs:/{Run_ID}/vectorizer'\n",
    "logged_model = f'runs:/{Run_ID}/model'\n",
    "loaded_vect = mlflow.sklearn.load_model(logged_vect)\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "# Preprocess the new raw text\n",
    "processed_text = preprocess_text(text)\n",
    "\n",
    "# Vectorize the processed text\n",
    "vectorized_text = loaded_vect.transform([processed_text])\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(vectorized_text)\n",
    "\n",
    "# Print the prediction\n",
    "print(f\"Predicted label: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will fetch all registered models   \n",
    "reg_models = mlflow.search_model_versions()\n",
    "\n",
    "len(reg_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelVersion: aliases=[], creation_timestamp=1691164375526, current_stage='Production', description='', last_updated_timestamp=1691169915423, name='spamfilter', run_id='ec6ebf18026749ad8e54420838c50561', run_link='', source='mlflow-artifacts:/771411303543058092/ec6ebf18026749ad8e54420838c50561/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='3'>,\n",
       " <ModelVersion: aliases=[], creation_timestamp=1691164359798, current_stage='None', description='', last_updated_timestamp=1691164359798, name='spamfilter', run_id='314f48e5798b4ef281dfa78675be6d8f', run_link='', source='mlflow-artifacts:/150244868769783183/314f48e5798b4ef281dfa78675be6d8f/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>,\n",
       " <ModelVersion: aliases=[], creation_timestamp=1691164332732, current_stage='None', description='', last_updated_timestamp=1691164332732, name='spamfilter', run_id='4dff1536413043218338cec6f2cad8cb', run_link='', source='mlflow-artifacts:/761930417213375925/4dff1536413043218338cec6f2cad8cb/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_model_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1691164375526, current_stage='None', description='', last_updated_timestamp=1691164375526, name='spamfilter', run_id='ec6ebf18026749ad8e54420838c50561', run_link='', source='mlflow-artifacts:/771411303543058092/ec6ebf18026749ad8e54420838c50561/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='3'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spamfilter', '3', 'READY', 'None'],\n",
       " ['spamfilter', '2', 'READY', 'None'],\n",
       " ['spamfilter', '1', 'READY', 'None']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[model.name, model.version, model.status, model.current_stage] for model in mlflow.search_model_versions()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_ID: ec6ebf18026749ad8e54420838c50561\n",
      "Model Name: spamfilter\n",
      "Version: 3\n"
     ]
    }
   ],
   "source": [
    "def get_production_model():\n",
    "    try:        \n",
    "        # This will fetch all registered models    \n",
    "        prod = [model for model in mlflow.search_model_versions() if model.name == 'spamfilter' and model.current_stage == 'Production'] \n",
    "        model = prod[0]            \n",
    "        print(f\"Run_ID: {model.run_id}\")\n",
    "        print(f\"Model Name: {model.name}\")\n",
    "        print(f\"Version: {model.version}\")               \n",
    "    except:\n",
    "        print(\"No Production Model Found\")\n",
    "\n",
    "get_production_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model name and version\n",
    "model_name = \"spamfilter\"\n",
    "model_version = \"production\"\n",
    "\n",
    "# Load the production model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "# Specify the artifact path for the vectorizer\n",
    "vectorizer_artifact_path = \"vectorizer\"\n",
    "\n",
    "# get run id by string operation\n",
    "run_id = str(loaded_model).split()[-1]\n",
    "\n",
    "# Load the vectorizer from the same run\n",
    "loaded_vectorizer = mlflow.sklearn.load_model(model_uri=f\"runs:/{run_id}/{vectorizer_artifact_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: spam\n"
     ]
    }
   ],
   "source": [
    "text = \"URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot!\"\n",
    "processed_text = preprocess_text(text)\n",
    "vectorized_text = loaded_vect.transform([processed_text])\n",
    "prediction = loaded_model.predict(vectorized_text)\n",
    "print(f\"Predicted label: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ec6ebf18026749ad8e54420838c50561'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(loaded_model).split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: model\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: ec6ebf18026749ad8e54420838c50561"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Production Model Found\n"
     ]
    }
   ],
   "source": [
    "def get_production_model():\n",
    "    try:        \n",
    "        # This will fetch all registered models    \n",
    "        prod = [model for model in mlflow.search_model_versions() if model.name == 'spamfilter' and model.current_stage == 'SAtged'] \n",
    "        model = prod[0]            \n",
    "        return model            \n",
    "    except:\n",
    "        print(\"No Production Model Found\")\n",
    "\n",
    "model = get_production_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spmf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
